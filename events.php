<?php
readfile("header.php");
?>

    <div class="container">
        <div class="container-sm">
            <h2>Events and Lectures
            </h2>
            <div id="year2018">
                <div class="event">
                    <h4>Friday, November 9, 2018 in Room 921 East Building, 1:00-2:00 pm (GRECS Seminar)
                    </h4>
                    <h3>Understanding outer automorphisms of free groups
                        using geodesics in Culler-Vogtmann outer space</h3>
                    <p>Presented by Catherine Pfaff, Asst. Professor of Mathematics, Queen's University at Kingston,
                        Ontario,
                        Canada <br><br> <span class="bold"> Abstract: </span>
                    </p>
                    <p>Outer space was defined by Culler and Vogtmann in 1986 as a simplicial complex (minus certain
                        faces)
                        on
                        which the
                        outer automorphism group of the free group would act nicely as a symmetry group. Through later
                        developments,
                        representatives of many of these outer automorphisms as geodesics were determined. In this talk
                        I
                        will
                        introduce
                        outer space, these geodesics, and several ways in which we've used them to understand outer
                        automorphisms of free
                        groups. <br><br><span class="bold">About the Speaker:</span></p>
                    <p>Catherine Pfaff is a tenure-track Assistant Professor of Mathematics at the Queen's University
                        at
                        Kingston in
                        Ontario, Canada. She received a PhD in Mathematics from Rutgers University at New Brunswick in
                        2012,
                        and has held
                        postdoctoral and visiting positions at the Aix-Marseille University, at the University of
                        Bielefeld,
                        and at the
                        University of California at Santa-Barbara. Catherine's research concentrates on the study of
                        algebraic,
                        probabilistic, dynamical and geometric properties of free group automorphisms.</p>
                </div>
                <div class="event">
                    <h4>Thursday, October 18, 2018 in the Hemmerdinger Screening Room, 7th Fl Library, 5:30-6:30 pm
                        (Department Colloquium)
                    </h4>
                    <h3>Fibres of Failure: Diagnosing Predictive Models Using Mapper
                    </h3>
                    <p>Presented by Prof. Mikael Veldemo-Johansson, Department of Mathematics, College of Staten
                        Island,
                        CUNY <br><br><span class="bold">Abstract:</span>
                    </p>
                    <p>The Mapper algorithm is able to produce intrinsic topological models of arbitrary data in high
                        dimensions. Through a
                        statistical adaptation of the Nerve lemma, the algorithm can be seen to reproduce the topology
                        and
                        parts of the
                        geometry of the data source under assumptions of dense sampling and good parameter choices. In
                        this
                        talk, we will
                        describe how by careful choice of the Mapper model parameters, the resulting topological model
                        can
                        be guaranteed to
                        separate input values to the predictive process for prediction error, grouping high-error and
                        low-error regions
                        separately. This approach produces a diagnostic process where local failure modes can be
                        classified, feeding into
                        either a model development process or a local correction term to improve predictive
                        performance. We
                        have
                        successfully applied this approach to temperature prediction in steel furnaces.
                    </p>
                </div>
                <div class="event">
                    <h4>Wednesday, October 17, 2018 in Room 920 East Building, 1:10-2:00 pm (Department Colloquium)
                    </h4>
                    <h3>An Invitation to Wikipedia Editing</h3>
                    <p>Presented by Prof. Ilya Kapovich, Department of Mathematics & Statistics, Hunter College, CUNY
                        <br><br><span class="bold">Abstract:</span></p>
                    <p>Wikipedia has become an indispensable resource that millions of people use every day as a source
                        of
                        knowledge and
                        information. Yet surprisingly few academics, including scientists and mathematicians, regularly
                        (or
                        ever) edit
                        Wikipedia. In this talk I will discuss the basics of becoming a Wikipedia editor, including the
                        main rules,
                        policies and differences in culture with the academic world. I will also show how to edit
                        Wikipedia
                        on
                        mathematical/scientific topics, both in terms of modifying existing Wikipedia articles and
                        creating
                        new ones. We
                        will conclude with a live demo of posting a brand new math article to Wikipedia. This talk is
                        intended for a broad
                        audience and no specific expertise in mathematics is required.
                    </p>
                </div>
                <div class="event">
                    <h4>Wednesday, September 26, 2018 in Room 921 East Building, 2:00-2:30 pm
                    </h4>
                    <h3>Consensus Estimates of Precipitation from
                        Diverse Data Sources in High Mountain Asia</h3>
                    <p>Presented by William F. Christensen, Chair of Statistics, Brigham Young University <br><br><span
                            class="bold">Abstract:</span></p>
                    <p>With the exception of the earth's polar regions, the High Mountain Asia region (including the
                        Tibetan Plateau)
                        contains more of the world's perennial glaciers than any other. Sometimes called the third pole
                        because of its
                        massive storage of ice, High Mountain Asia (HMA) provides water to one-fifth of the world's
                        population. Due to
                        changes in precipitation patterns and temperatures warming faster in HMA than the global
                        average,
                        the region faces
                        increased risk of flooding, crop damage, mudslides, economic instability, and long-term water
                        shortages for the
                        communities down-river. In this talk, we discuss a large, interdisciplinary,
                        multi-institutional
                        research project
                        for characterizing climate change in HMA. We illustrate the use of latent variable models for
                        extracting consensus
                        estimates of spatiotemporally-correlated climate processes from a suite of climate model
                        outputs
                        and remote-sensing
                        observations, and we discuss the uncertainty quantification needed to inform probability-based
                        decision making. We
                        conclude with a discussion of decision making, uncertainty, and the important role of
                        statisticians
                        in framing the
                        public debate about climate change abatement.
                    </p>
                </div>
                <div class="event">
                    <h4>Tuesday, April 24, 2018 in Room 920 East Building, 3:00-4:00 pm (GRECS Seminar)
                    </h4>
                    <h3>Algorithmic problems for quasiconvex subgroups of hyperbolic groups
                    </h3>
                    <p>Presented by Eric Swenson, Professor of Mathematics, Brigham Young University
                        <br><br><span class="bold">Abstract:</span></p>
                    <p>We discuss algorithms for determining whether a quasiconvex subgroup is almost malnormal and an
                        algorithm for
                        determining the numbers of ends of the pair for a quasiconvex subgroup.
                    </p>
                </div>
                <div class="event">
                    <h4>Friday, March 9, 2018 in Room 920 East Building, 12 noon-1:00 pm
                    </h4>
                    <h3>Methods and Software Development for
                        Interval-Censored Time-to-Event Data</h3>
                    <p>Presented by Chun Pan, Clinical Biostatistician, Novartis Oncology
                        <br><br><span class="bold">Abstract:</span></p>
                    <p>Interval-censored time-to-event data occur naturally in studies of diseases where the symptoms
                        of
                        interest are not
                        directly observable, and periodic laboratory or clinical examinations are required for
                        detection.
                        Due to the lack
                        of well- established procedures, interval-censored data have been conventionally treated as
                        right-censored data;
                        however, this introduces bias at the first place. This presentation gives an overview of my
                        current
                        research, which
                        focuses on methodological research and software development for analyzing interval- censored
                        data.
                        Specifically, it
                        will present the three research projects that have been completed. The first project is a
                        Bayesian
                        semiparametric
                        proportional hazards model with spatial random effect for spatially correlated interval-
                        censored
                        data. In the
                        second project, we developed a multiple frailty proportional hazards model with frailty
                        selection
                        for clustered
                        interval-censored data, which is analogous to a mixed model in regression analysis. In the
                        third
                        project, we
                        created an R package “ICBayes” for regression analysis and survival curve estimation of
                        interval-censored data
                        based on several published papers by our research team. At the end, this presentation will lay
                        out
                        some directions
                        for future research.
                    </p>
                </div>
                <div class="event">
                    <h4>Friday, March 2, 2018 in Room 920 East Building, 12 noon-1:00 pm
                    </h4>
                    <h3>Robust Nonparametric Functional Data Analysis
                        Based on Depth </h3>
                    <p>Presented by Sara Lopez-Pintado, Professor of Statistics, Columbia University <br> <br><span
                            class="bold">Abstract:</span>
                    </p>
                    <p>Technological development in many emerging research fields has led to the acquisition of large
                        collections of data
                        of extraordinary complexity. In neuroscience for example, brain-imaging technology has provided
                        us
                        with complex
                        collections of signals from individuals in different neurophysiological states in healthy and
                        diseased populations.
                        These signals can be collected and represented as functions. The development of statistical
                        tools
                        to analyze this
                        type of high-dimensional data set is very much needed. I will present new robust methodologies
                        for
                        analyzing
                        functional and imaging data based on the concept of depth. Functional depth provides a rigorous
                        way
                        of ranking a
                        sample of functions from center-outward. This ordering allows us to define robust descriptive
                        statistics such as
                        medians, trimmed means and central regions for functional data. Moreover, data depth is often
                        used
                        as a building
                        block for developing robust statistical methods and outlier-detection techniques. Permutation
                        and
                        global envelope
                        depth-based tests for comparing the locations of two groups of functions or images are proposed
                        and
                        calibrated. The
                        performances of these methods are illustrated in simulated and real data sets. In particular,
                        we
                        tested differences
                        between PET (Positron Emission Tomography) brain images of healthy controls and patients with
                        severe depression. We
                        also used these methods to test differences between the growth pattern of normal and low birth
                        weight children.
                    </p>

                </div>
                <div class="event">
                    <h4>Friday, February 23, 2018 in Room 920 East Building, 12 noon-1:00 pm
                    </h4>
                    <h3>Constrained Factor Models for High-Dimensional
                        Matrix-Variate Time Series</h3>
                    <p>Presented by Elynn Chen, Statistics PhD Candidate, Rutgers University
                        <br><br><span class="bold">Abstract:</span></p>
                    <p>High-dimensional matrix-variate time series data are becoming widely available in many
                        scientific
                        fields, such as
                        economics, biology, and meteorology. To achieve significant dimension reduction while
                        preserving
                        the intrinsic
                        matrix structure and temporal dynamics in such data, Wang et al. 2017 proposed a matrix factor
                        model that is shown
                        to provide effective analysis. In this paper, we establish a general framework for
                        incorporating
                        domain or prior
                        knowledge in the matrix factor model through linear constraints. The proposed framework is
                        shown to
                        be useful in
                        achieving parsimonious parameterization, facilitating interpretation of the latent matrix
                        factor,
                        and identifying
                        specific factors of interest. Fully utilizing the prior-knowledge-induced constraints results
                        in
                        more efficient and
                        accurate modeling, inference, dimension reduction as well as a clear and better interpretation
                        of
                        the results. In
                        this paper, constrained, multi-term, and partially constrained factor models for matrix-variate
                        time series are
                        developed, with efficient estimation procedures and their asymptotic properties. We show that
                        the
                        convergence rates
                        of the constrained factor loading matrices are much faster than those of the conventional
                        matrix
                        factor analysis
                        uweender many situations. Simulation studies are carried out to demonstrate the finite-sample
                        performance of the
                        proposed method and its associated asymptotic properties. We illustrate the proposed model with
                        three applications,
                        where the constrained matrix-factor models outperform their unconstrained counterparts in the
                        power
                        of variance
                        explanation under the out-of-sample 10-fold cross-validation setting.
                    </p>
                </div>
            </div>
            <div class="year2017">
                <div class="event">
                    <h4>Wednesday, December 13, 2017 in Room 921 East Building, 3:00-4:00 pm (GRECS Seminar)
                    </h4>
                    <h3>Infinite Periodic Groups and Burnside Problems
                    </h3>
                    <p>Presented by Diljit Singh, Mathematics Major at Hunter College
                        <br><br><span class="bold">Abstract:</span></p>
                    <p>We will talk about different formulations of Burnside's problems and list major milestones
                        towards the 1994 result
                        by Zelmanov. We will sketch a short proof of the Golod and Shafarevich theorem and the
                        construction of a
                        counterexample to the General Burnside Problem.
                    </p>
                </div>
                <div class="event">
                    <h4>Wednesday, November29, 2017 in Room 921 East Building, 1:15-2:15 pm (CUNY Applied Probability
                        and Statistics
                        Seminar)
                    </h4>
                    <h3>Analysis of Error Control in Large Scale Two-Stage Multiple Hypothesis Testing</h3>
                    <p>Presented by Wenge Guo, Associate Professor of Statistics, New Jersey Institute of Technology
                        <br><br><span class="bold">Abstract:</span>
                        <p>When dealing with the problem of simultaneously testing a large number of null hypotheses, a
                            natural testing
                            strategy is to first reduce the number of tested hypotheses by doing screening or
                            selection, and then to
                            simultaneously test selected hypotheses. The main advantage of this strategy is to greatly
                            reduce the severe effect
                            of high dimensions. However, the first screening or selection stage must be properly
                            accounted for in order to
                            maintain some type of error control. In this talk, we will introduce a selection rule based
                            on the selection
                            statistic which is independent of the test statistic when the tested hypothesis is true.
                            Combining this selection
                            rule and the conventional Bonferroni procedure, we can develop a powerful and valid
                            two-stage procedure. The
                            suggested procedure has several nice properties: (i) completely remove the selection
                            effect; (ii) reduce the
                            multiplicity effect; (iii) do not waste any samples while carrying out both selection and
                            testing. Asymptotic power
                            analysis and simulation studies illustrate that this proposed method provides higher power
                            compared to usual
                            multiple testing methods while controlling the type 1 error rate. Optimal selection
                            thresholds are also derived
                            based on our asymptotic analysis. This is a joint work with Joseph Romano from Stanford
                            University.
                        </p>
                    </p>
                </div>
            </div>

        </div>
    </div>
    <?php
    readfile("footer.php");
    ?>